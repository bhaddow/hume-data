\section{Executive Summary}

This document provides a summary of the work done in the first year of the HimL project in the
evaluation work package 5. 
The objectives of this work package are to develop human and automatic accuracy-based evaluation strategies 
for machine translation, and to carefully evaluate the quality and impact of the innovations we deliver to 
NHS24 and Cochrane.

The first section in this report describes the creation of the HimL test set from our use case partners.
We then describe experiments where we apply these test sets to the HimL  machine translation systems,
and we report the first results for our models on in-domain data. 
  
The next section describes the evaluation plan which we developed in close collaboration with NHS24 and Cochrane.
Work package 5 is responsible for the thorough evaluation of translation systems. 
Although automatic metrics give indications of the quality of the translations, they
are not good at capturing accuracy or usefulness. Accuracy needs to be investigated using human evaluation which is 
very time consuming and expensive. The
evaluation plan allows us to map out the schedule of these evaluations 
and defines the  types of evaluation that both the academic
partners and the use case partners will most benefit from. 
  
The last section of this report describes the development of our human semantic evaluation method. 
  This evaluation uses semantic trees on the source sentence and asks
 bilingual annotators to label 
%what 
which
parts of the tree have been correctly translated. 
 In this way we are able to quantify how much of the meaning of the source sentence has been
 retained 
%on the target. 
in the translation.
Having multiple annotators for two language pairs allowed us to
investigate inter-annotator agreement, and results show that this approach is reliable. 
This human evaluation comprises the first year's user acceptance testing. 



\begin{table}[h!]
\begin{center}
      \begin{tabular}{|l|l|l|p{6.5cm}|}
      \hline
      
\bf{Task} & \bf{Description} & \bf{Planned Schedule}  & \bf{Status } \\
\hline                               
     5.1   & Test corpora for the required language pairs & M1-M6  & Complete  \\ 
     5.2   & Human Semantic MT Evaluation Metric &  M1-M12 & Complete \\ 
     5.3   & Automatic Semantic MT Evaluation Metric & M6-M18  &  Initiated \\ 
     5.4   & User acceptance testing &  M9-M12 annually  &  Year 1 testing completed as part of Task 5.2 \\ 
     5.5   & Evaluation of the impact &  M6-M36 & Planning complete, started data collection  \\ 
 
      \hline
    \end{tabular}
\end{center}
\normalsize
\vspace*{-3ex}
\caption{Tasks in workpackage 5, their dates and their status as of 31/Jan/2016
}
\label{tab:tasksschedule}
\end{table}

 Table~\ref{tab:tasksschedule} summarises the status of the tasks in the evaluation workpackage. 
We can see that all tasks are currently on schedule and that puts us in a strong position
to succeed in delivering the work promised in year two and three of the HimL project.
 